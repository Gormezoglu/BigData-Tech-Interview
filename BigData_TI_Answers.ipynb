{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ybl-OTpuiQx"
      },
      "source": [
        "## Task -1 Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q2FGpclC3tn4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running command: sudo apt-get update -qq\n",
            "Running command: sudo apt install -y openjdk-8-jdk-headless\n",
            "Reading package lists...\n",
            "\n",
            "Building dependency tree...\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "Reading state information...\n",
            "\n",
            "openjdk-8-jdk-headless is already the newest version (8u392-ga-1~20.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Running command: sudo wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
            "Running command: sudo tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
            "Running command: sudo pip install -q findspark\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Installing Spark with its dependencies\n",
        "Installing Spark\n",
        "Install Dependencies:\n",
        "\n",
        "Java 8\n",
        "Apache Spark with hadoop and\n",
        "Findspark (used to locate the spark in the system)\n",
        "\"\"\"\n",
        "\n",
        "!sudo ./install_spark.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1vd9yVaK4DR6"
      },
      "outputs": [],
      "source": [
        "#Set Environment Variables:\n",
        "\n",
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = os.path.join(current_directory,\"spark-3.1.1-bin-hadoop3.2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "SUjv6TWh4i1t",
        "outputId": "9bb2d972-e87e-43fb-d2f5-fca2dd7c7b1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 14:59:20 WARN Utils: Your hostname, codespaces-7047d6 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
            "24/01/23 14:59:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "24/01/23 14:59:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a08ece89-43be-495d-a4c4-f02eb4265d4a.internal.cloudapp.net:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MovieLens</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f4dd75cb370>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#Create a SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"MovieLens\") \\\n",
        "    .config(\"spark.jars\", \"spark-3.1.1-bin-hadoop3.2/jars/sqlite-jdbc-3.34.0.jar\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2mYOKttpn9EH"
      },
      "outputs": [],
      "source": [
        "#will be used sqlite3 to be able to reach .db file\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "con = sqlite3.connect('Datasets/movielens-small.db')\n",
        "cur = con.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Table: movies\n",
            "0: movieId: INT\n",
            "1: title: TEXT\n",
            "2: year: INT\n",
            "3: genres: TEXT\n",
            "\n",
            "Table: ratings\n",
            "0: userId: INT\n",
            "1: movieId: INT\n",
            "2: rating: REAL\n",
            "3: timestamp: INT\n",
            "\n",
            "Table: links\n",
            "0: movieId: INT\n",
            "1: imdbId: TEXT\n",
            "2: tmdbId: TEXT\n",
            "\n",
            "Table: tags\n",
            "0: userId: INT\n",
            "1: movieId: INT\n",
            "2: tag: TEXT\n",
            "3: timestamp: NUM\n"
          ]
        }
      ],
      "source": [
        "# Get the field information of each table in the database\n",
        "\n",
        "# Define a function to print table information in a readable way\n",
        "def print_table_info(table_name, table_info):\n",
        "    print(f\"\\nTable: {table_name}\")\n",
        "    for row in table_info:\n",
        "        print(row[0], row[1], row[2],sep=\": \")\n",
        "\n",
        "# Get and print information for the 'movies' table\n",
        "cur.execute(\"PRAGMA table_info(movies);\")\n",
        "movies_info = cur.fetchall()\n",
        "print_table_info(\"movies\", movies_info)\n",
        "\n",
        "# Get and print information for the 'ratings' table\n",
        "cur.execute(\"PRAGMA table_info(ratings);\")\n",
        "ratings_info = cur.fetchall()\n",
        "print_table_info(\"ratings\", ratings_info)\n",
        "\n",
        "# Get and print information for the 'links' table\n",
        "cur.execute(\"PRAGMA table_info(links);\")\n",
        "links_info = cur.fetchall()\n",
        "print_table_info(\"links\", links_info)\n",
        "\n",
        "# Get and print information for the 'tags' table\n",
        "cur.execute(\"PRAGMA table_info(tags);\")\n",
        "tags_info = cur.fetchall()\n",
        "print_table_info(\"tags\", tags_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OahMiKvLqz6p",
        "outputId": "9b7a9f5d-808f-409d-e6fa-8b5d122c5de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7125k  100 7125k    0     0  51.9M      0 --:--:-- --:--:-- --:--:-- 51.9M\n"
          ]
        }
      ],
      "source": [
        "#For SQLite JDBC driver, it can be downloaded via:\n",
        "\n",
        "!curl -O https://repo1.maven.org/maven2/org/xerial/sqlite-jdbc/3.34.0/sqlite-jdbc-3.34.0.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HikariCP-2.5.1.jar\n",
            "JLargeArrays-1.5.jar\n",
            "JTransforms-3.1.jar\n",
            "RoaringBitmap-0.9.0.jar\n",
            "ST4-4.0.4.jar\n",
            "accessors-smart-1.2.jar\n",
            "activation-1.1.1.jar\n",
            "aircompressor-0.10.jar\n",
            "algebra_2.12-2.0.0-M2.jar\n",
            "antlr-runtime-3.5.2.jar\n",
            "antlr4-runtime-4.8-1.jar\n",
            "aopalliance-1.0.jar\n",
            "aopalliance-repackaged-2.6.1.jar\n",
            "arpack_combined_all-0.1.jar\n",
            "arrow-format-2.0.0.jar\n",
            "arrow-memory-core-2.0.0.jar\n",
            "arrow-memory-netty-2.0.0.jar\n",
            "arrow-vector-2.0.0.jar\n",
            "audience-annotations-0.5.0.jar\n",
            "automaton-1.11-8.jar\n",
            "avro-1.8.2.jar\n",
            "avro-ipc-1.8.2.jar\n",
            "avro-mapred-1.8.2-hadoop2.jar\n",
            "bonecp-0.8.0.RELEASE.jar\n",
            "breeze-macros_2.12-1.0.jar\n",
            "breeze_2.12-1.0.jar\n",
            "cats-kernel_2.12-2.0.0-M4.jar\n",
            "chill-java-0.9.5.jar\n",
            "chill_2.12-0.9.5.jar\n",
            "commons-beanutils-1.9.4.jar\n",
            "commons-cli-1.2.jar\n",
            "commons-codec-1.10.jar\n",
            "commons-collections-3.2.2.jar\n",
            "commons-compiler-3.0.16.jar\n",
            "commons-compress-1.20.jar\n",
            "commons-configuration2-2.1.1.jar\n",
            "commons-crypto-1.1.0.jar\n",
            "commons-daemon-1.0.13.jar\n",
            "commons-dbcp-1.4.jar\n",
            "commons-httpclient-3.1.jar\n",
            "commons-io-2.5.jar\n",
            "commons-lang-2.6.jar\n",
            "commons-lang3-3.10.jar\n",
            "commons-logging-1.1.3.jar\n",
            "commons-math3-3.4.1.jar\n",
            "commons-net-3.1.jar\n",
            "commons-pool-1.5.4.jar\n",
            "commons-text-1.6.jar\n",
            "compress-lzf-1.0.3.jar\n",
            "core-1.1.2.jar\n",
            "curator-client-2.13.0.jar\n",
            "curator-framework-2.13.0.jar\n",
            "curator-recipes-2.13.0.jar\n",
            "datanucleus-api-jdo-4.2.4.jar\n",
            "datanucleus-core-4.1.17.jar\n",
            "datanucleus-rdbms-4.1.19.jar\n",
            "derby-10.12.1.1.jar\n",
            "dnsjava-2.1.7.jar\n",
            "dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "ehcache-3.3.1.jar\n",
            "flatbuffers-java-1.9.0.jar\n",
            "generex-1.0.2.jar\n",
            "geronimo-jcache_1.0_spec-1.0-alpha-1.jar\n",
            "gson-2.2.4.jar\n",
            "guava-14.0.1.jar\n",
            "guice-4.0.jar\n",
            "guice-servlet-4.0.jar\n",
            "hadoop-annotations-3.2.0.jar\n",
            "hadoop-auth-3.2.0.jar\n",
            "hadoop-client-3.2.0.jar\n",
            "hadoop-common-3.2.0.jar\n",
            "hadoop-hdfs-client-3.2.0.jar\n",
            "hadoop-mapreduce-client-common-3.2.0.jar\n",
            "hadoop-mapreduce-client-core-3.2.0.jar\n",
            "hadoop-mapreduce-client-jobclient-3.2.0.jar\n",
            "hadoop-yarn-api-3.2.0.jar\n",
            "hadoop-yarn-client-3.2.0.jar\n",
            "hadoop-yarn-common-3.2.0.jar\n",
            "hadoop-yarn-registry-3.2.0.jar\n",
            "hadoop-yarn-server-common-3.2.0.jar\n",
            "hadoop-yarn-server-web-proxy-3.2.0.jar\n",
            "hive-beeline-2.3.7.jar\n",
            "hive-cli-2.3.7.jar\n",
            "hive-common-2.3.7.jar\n",
            "hive-exec-2.3.7-core.jar\n",
            "hive-jdbc-2.3.7.jar\n",
            "hive-llap-common-2.3.7.jar\n",
            "hive-metastore-2.3.7.jar\n",
            "hive-serde-2.3.7.jar\n",
            "hive-service-rpc-3.1.2.jar\n",
            "hive-shims-0.23-2.3.7.jar\n",
            "hive-shims-2.3.7.jar\n",
            "hive-shims-common-2.3.7.jar\n",
            "hive-shims-scheduler-2.3.7.jar\n",
            "hive-storage-api-2.7.2.jar\n",
            "hive-vector-code-gen-2.3.7.jar\n",
            "hk2-api-2.6.1.jar\n",
            "hk2-locator-2.6.1.jar\n",
            "hk2-utils-2.6.1.jar\n",
            "htrace-core4-4.1.0-incubating.jar\n",
            "httpclient-4.5.6.jar\n",
            "httpcore-4.4.12.jar\n",
            "istack-commons-runtime-3.0.8.jar\n",
            "ivy-2.4.0.jar\n",
            "jackson-annotations-2.10.0.jar\n",
            "jackson-core-2.10.0.jar\n",
            "jackson-core-asl-1.9.13.jar\n",
            "jackson-databind-2.10.0.jar\n",
            "jackson-dataformat-yaml-2.10.0.jar\n",
            "jackson-datatype-jsr310-2.11.2.jar\n",
            "jackson-jaxrs-base-2.9.5.jar\n",
            "jackson-jaxrs-json-provider-2.9.5.jar\n",
            "jackson-mapper-asl-1.9.13.jar\n",
            "jackson-module-jaxb-annotations-2.10.0.jar\n",
            "jackson-module-paranamer-2.10.0.jar\n",
            "jackson-module-scala_2.12-2.10.0.jar\n",
            "jakarta.activation-api-1.2.1.jar\n",
            "jakarta.annotation-api-1.3.5.jar\n",
            "jakarta.inject-2.6.1.jar\n",
            "jakarta.servlet-api-4.0.3.jar\n",
            "jakarta.validation-api-2.0.2.jar\n",
            "jakarta.ws.rs-api-2.1.6.jar\n",
            "jakarta.xml.bind-api-2.3.2.jar\n",
            "janino-3.0.16.jar\n",
            "javassist-3.25.0-GA.jar\n",
            "javax.inject-1.jar\n",
            "javax.jdo-3.2.0-m3.jar\n",
            "javolution-5.5.1.jar\n",
            "jaxb-api-2.2.11.jar\n",
            "jaxb-runtime-2.3.2.jar\n",
            "jcip-annotations-1.0-1.jar\n",
            "jcl-over-slf4j-1.7.30.jar\n",
            "jdo-api-3.0.1.jar\n",
            "jersey-client-2.30.jar\n",
            "jersey-common-2.30.jar\n",
            "jersey-container-servlet-2.30.jar\n",
            "jersey-container-servlet-core-2.30.jar\n",
            "jersey-hk2-2.30.jar\n",
            "jersey-media-jaxb-2.30.jar\n",
            "jersey-server-2.30.jar\n",
            "jline-2.14.6.jar\n",
            "joda-time-2.10.5.jar\n",
            "jodd-core-3.5.2.jar\n",
            "jpam-1.1.jar\n",
            "json-1.8.jar\n",
            "json-smart-2.3.jar\n",
            "json4s-ast_2.12-3.7.0-M5.jar\n",
            "json4s-core_2.12-3.7.0-M5.jar\n",
            "json4s-jackson_2.12-3.7.0-M5.jar\n",
            "json4s-scalap_2.12-3.7.0-M5.jar\n",
            "jsp-api-2.1.jar\n",
            "jsr305-3.0.0.jar\n",
            "jta-1.1.jar\n",
            "jul-to-slf4j-1.7.30.jar\n",
            "kerb-admin-1.0.1.jar\n",
            "kerb-client-1.0.1.jar\n",
            "kerb-common-1.0.1.jar\n",
            "kerb-core-1.0.1.jar\n",
            "kerb-crypto-1.0.1.jar\n",
            "kerb-identity-1.0.1.jar\n",
            "kerb-server-1.0.1.jar\n",
            "kerb-simplekdc-1.0.1.jar\n",
            "kerb-util-1.0.1.jar\n",
            "kerby-asn1-1.0.1.jar\n",
            "kerby-config-1.0.1.jar\n",
            "kerby-pkix-1.0.1.jar\n",
            "kerby-util-1.0.1.jar\n",
            "kerby-xdr-1.0.1.jar\n",
            "kryo-shaded-4.0.2.jar\n",
            "kubernetes-client-4.12.0.jar\n",
            "kubernetes-model-admissionregistration-4.12.0.jar\n",
            "kubernetes-model-apiextensions-4.12.0.jar\n",
            "kubernetes-model-apps-4.12.0.jar\n",
            "kubernetes-model-autoscaling-4.12.0.jar\n",
            "kubernetes-model-batch-4.12.0.jar\n",
            "kubernetes-model-certificates-4.12.0.jar\n",
            "kubernetes-model-common-4.12.0.jar\n",
            "kubernetes-model-coordination-4.12.0.jar\n",
            "kubernetes-model-core-4.12.0.jar\n",
            "kubernetes-model-discovery-4.12.0.jar\n",
            "kubernetes-model-events-4.12.0.jar\n",
            "kubernetes-model-extensions-4.12.0.jar\n",
            "kubernetes-model-metrics-4.12.0.jar\n",
            "kubernetes-model-networking-4.12.0.jar\n",
            "kubernetes-model-policy-4.12.0.jar\n",
            "kubernetes-model-rbac-4.12.0.jar\n",
            "kubernetes-model-scheduling-4.12.0.jar\n",
            "kubernetes-model-settings-4.12.0.jar\n",
            "kubernetes-model-storageclass-4.12.0.jar\n",
            "leveldbjni-all-1.8.jar\n",
            "libfb303-0.9.3.jar\n",
            "libthrift-0.12.0.jar\n",
            "log4j-1.2.17.jar\n",
            "logging-interceptor-3.12.12.jar\n",
            "lz4-java-1.7.1.jar\n",
            "machinist_2.12-0.6.8.jar\n",
            "macro-compat_2.12-1.1.1.jar\n",
            "mesos-1.4.0-shaded-protobuf.jar\n",
            "metrics-core-4.1.1.jar\n",
            "metrics-graphite-4.1.1.jar\n",
            "metrics-jmx-4.1.1.jar\n",
            "metrics-json-4.1.1.jar\n",
            "metrics-jvm-4.1.1.jar\n",
            "minlog-1.3.0.jar\n",
            "netty-all-4.1.51.Final.jar\n",
            "nimbus-jose-jwt-4.41.1.jar\n",
            "objenesis-2.6.jar\n",
            "okhttp-2.7.5.jar\n",
            "okhttp-3.12.12.jar\n",
            "okio-1.14.0.jar\n",
            "opencsv-2.3.jar\n",
            "orc-core-1.5.12.jar\n",
            "orc-mapreduce-1.5.12.jar\n",
            "orc-shims-1.5.12.jar\n",
            "oro-2.0.8.jar\n",
            "osgi-resource-locator-1.0.3.jar\n",
            "paranamer-2.8.jar\n",
            "parquet-column-1.10.1.jar\n",
            "parquet-common-1.10.1.jar\n",
            "parquet-encoding-1.10.1.jar\n",
            "parquet-format-2.4.0.jar\n",
            "parquet-hadoop-1.10.1.jar\n",
            "parquet-jackson-1.10.1.jar\n",
            "protobuf-java-2.5.0.jar\n",
            "py4j-0.10.9.jar\n",
            "pyrolite-4.30.jar\n",
            "re2j-1.1.jar\n",
            "scala-collection-compat_2.12-2.1.1.jar\n",
            "scala-compiler-2.12.10.jar\n",
            "scala-library-2.12.10.jar\n",
            "scala-parser-combinators_2.12-1.1.2.jar\n",
            "scala-reflect-2.12.10.jar\n",
            "scala-xml_2.12-1.2.0.jar\n",
            "shapeless_2.12-2.3.3.jar\n",
            "shims-0.9.0.jar\n",
            "slf4j-api-1.7.30.jar\n",
            "slf4j-log4j12-1.7.30.jar\n",
            "snakeyaml-1.24.jar\n",
            "snappy-java-1.1.8.2.jar\n",
            "spark-catalyst_2.12-3.1.1.jar\n",
            "spark-core_2.12-3.1.1.jar\n",
            "spark-graphx_2.12-3.1.1.jar\n",
            "spark-hive-thriftserver_2.12-3.1.1.jar\n",
            "spark-hive_2.12-3.1.1.jar\n",
            "spark-kubernetes_2.12-3.1.1.jar\n",
            "spark-kvstore_2.12-3.1.1.jar\n",
            "spark-launcher_2.12-3.1.1.jar\n",
            "spark-mesos_2.12-3.1.1.jar\n",
            "spark-mllib-local_2.12-3.1.1.jar\n",
            "spark-mllib_2.12-3.1.1.jar\n",
            "spark-network-common_2.12-3.1.1.jar\n",
            "spark-network-shuffle_2.12-3.1.1.jar\n",
            "spark-repl_2.12-3.1.1.jar\n",
            "spark-sketch_2.12-3.1.1.jar\n",
            "spark-sql_2.12-3.1.1.jar\n",
            "spark-streaming_2.12-3.1.1.jar\n",
            "spark-tags_2.12-3.1.1-tests.jar\n",
            "spark-tags_2.12-3.1.1.jar\n",
            "spark-unsafe_2.12-3.1.1.jar\n",
            "spark-yarn_2.12-3.1.1.jar\n",
            "spire-macros_2.12-0.17.0-M1.jar\n",
            "spire-platform_2.12-0.17.0-M1.jar\n",
            "spire-util_2.12-0.17.0-M1.jar\n",
            "spire_2.12-0.17.0-M1.jar\n",
            "sqlite-jdbc-3.34.0.jar\n",
            "stax-api-1.0.1.jar\n",
            "stax2-api-3.1.4.jar\n",
            "stream-2.9.6.jar\n",
            "super-csv-2.2.0.jar\n",
            "threeten-extra-1.5.0.jar\n",
            "token-provider-1.0.1.jar\n",
            "transaction-api-1.1.jar\n",
            "univocity-parsers-2.9.1.jar\n",
            "velocity-1.5.jar\n",
            "woodstox-core-5.0.3.jar\n",
            "xbean-asm7-shaded-4.15.jar\n",
            "xz-1.5.jar\n",
            "zjsonpatch-0.3.0.jar\n",
            "zookeeper-3.4.14.jar\n",
            "zstd-jni-1.4.8-1.jar\n"
          ]
        }
      ],
      "source": [
        "# install sqlite-jdbc-3.34.0.jar to the spark/jars directory\n",
        "\n",
        "!sudo cp sqlite-jdbc-3.34.0.jar spark-3.1.1-bin-hadoop3.2/jars/\n",
        "\n",
        "#check the jar file is in the spark/jars directory\n",
        "\n",
        "!ls spark-3.1.1-bin-hadoop3.2/jars/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a dataframe with including userid, movieid, genre and rating via pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Read the ratings table into a dataframe\n",
        "ratings_df = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:sqlite:Datasets/movielens-small.db\") \\\n",
        "    .option(\"dbtable\", \"ratings\") \\\n",
        "    .load()\n",
        "\n",
        "# Read the movies table into a dataframe\n",
        "movies_df = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:sqlite:Datasets/movielens-small.db\") \\\n",
        "    .option(\"dbtable\", \"movies\") \\\n",
        "    .load()\n",
        "\n",
        "# Read the links table into a dataframe\n",
        "links_df = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:sqlite:Datasets/movielens-small.db\") \\\n",
        "    .option(\"dbtable\", \"links\") \\\n",
        "    .load()\n",
        "\n",
        "# Read the tags table into a dataframe\n",
        "tags_df = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:sqlite:Datasets/movielens-small.db\") \\\n",
        "    .option(\"dbtable\", \"tags\") \\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+------+------+\n",
            "|userId|movieId|genres|rating|\n",
            "+------+-------+------+------+\n",
            "|    14|     26| Drama|   4.0|\n",
            "|    31|     26| Drama|   2.0|\n",
            "|    51|     26| Drama|   4.0|\n",
            "|    79|     26| Drama|   4.0|\n",
            "|   156|     26| Drama|   4.0|\n",
            "|   161|     26| Drama|   3.0|\n",
            "|   203|     26| Drama|   4.0|\n",
            "|   219|     26| Drama|   3.0|\n",
            "|   220|     26| Drama|   2.5|\n",
            "|   228|     26| Drama|   4.0|\n",
            "+------+-------+------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "100023"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write a query to create a dataframe with including userid, movieid, genre and rating\n",
        "\n",
        "\n",
        "# join ratings and movies dataframes on movieid column and create a new dataframe called ratings_movies_df via pyspark dataframe\n",
        "ratings_movies_df = ratings_df.join(movies_df, on=\"movieId\", how=\"left\")\n",
        "\n",
        "# show the userid, movieid, genre and rating columns of ratings_movies_df dataframe\n",
        "ratings_movies_df.select(\"userId\", \"movieId\", \"genres\", \"rating\").show(10)\n",
        "\n",
        "#count the number of rows in ratings_movies_df dataframe\n",
        "ratings_movies_df.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adqNcucRA00",
        "outputId": "c08790f9-8ab1-4de5-8c3f-958c4d1c7365"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 10:================================================>     (180 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------------+------------+\n",
            "|movieId|title                    |rating_count|\n",
            "+-------+-------------------------+------------+\n",
            "|593    |Silence of the Lambs, The|337         |\n",
            "|318    |Shawshank Redemption, The|328         |\n",
            "|296    |Pulp Fiction             |327         |\n",
            "|480    |Jurassic Park            |324         |\n",
            "|356    |Forrest Gump             |318         |\n",
            "+-------+-------------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Count ratings for each movie, and list top 5 movies with the highest value\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Calculate the count of ratings for each movie\n",
        "movie_rating_count_df = ratings_movies_df.groupBy(\"movieId\").agg(\n",
        "    F.count(\"rating\").alias(\"rating_count\")\n",
        ")\n",
        "\n",
        "# Join the top_movies_df with the movies_df dataframe to get the movie titles\n",
        "top_movies_df = movie_rating_count_df.join(movies_df, on=\"movieId\", how=\"left\")\n",
        "\n",
        "top_movies_df.select(\"movieId\", \"title\", \"rating_count\").sort(\"rating_count\", ascending=False).show(5, truncate=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgVd_W6qkFC_",
        "outputId": "7dccc28f-4a43-4244-dc05-5c1aacdb347d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 14:===================================================>  (190 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+------------+\n",
            "|genres        |rating_count|\n",
            "+--------------+------------+\n",
            "|Drama         |7008        |\n",
            "|Comedy        |6396        |\n",
            "|Comedy|Romance|3877        |\n",
            "|Drama|Romance |3121        |\n",
            "|Comedy|Drama  |3000        |\n",
            "+--------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Find and list top 5 most rated genres\n",
        "\n",
        "genre_rating_count_df = ratings_movies_df.groupBy(\"genres\").agg(\n",
        "    F.count(\"rating\").alias(\"rating_count\")\n",
        ")\n",
        "\n",
        "genre_rating_count_df.sort(\"rating_count\", ascending=False).show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4OzuDxlcDsL",
        "outputId": "ef97a8b8-5517-495c-a035-56c6c1562f5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 18:==================================================>   (188 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+------------+\n",
            "|tag         |rating_count|\n",
            "+------------+------------+\n",
            "|drama       |3542        |\n",
            "|sci-fi      |3035        |\n",
            "|twist ending|2998        |\n",
            "|psychology  |2672        |\n",
            "|crime       |2570        |\n",
            "+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Find and list top 5 most rated tags except null values\n",
        "\n",
        "tags_rating_count_df = ratings_movies_df.join(tags_df, on=\"movieId\", how=\"left\").groupBy(\"tag\").agg(\n",
        "    F.count(\"rating\").alias(\"rating_count\")).filter(tags_df.tag.isNotNull())\n",
        "\n",
        "tags_rating_count_df.sort(\"rating_count\", ascending=False).show(5, truncate=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zWDyIsOk-uz",
        "outputId": "d4ad6c27-10c1-4f19-ad5e-e837a26c8012"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 23:=========================================>            (154 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---------------+\n",
            "|userId|timestamp_count|\n",
            "+------+---------------+\n",
            "|516   |2268           |\n",
            "|384   |1412           |\n",
            "|187   |1338           |\n",
            "|31    |1283           |\n",
            "|377   |1241           |\n",
            "+------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# By using timestamp from ratings table, provide top 5 most frequent users within a week\n",
        "\n",
        "genre_rating_count_df = ratings_movies_df.groupBy(\"userId\").agg(\n",
        "    F.count(\"timestamp\").alias(\"timestamp_count\")\n",
        ")\n",
        "\n",
        "genre_rating_count_df.sort(\"timestamp_count\", ascending=False).show(5, truncate=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK3PElZAxM7a",
        "outputId": "30ae116e-0681-41a4-84d1-f1d14be82561"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 27:=====================================================>(197 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------+----------+\n",
            "|genres                                                  |rating_avg|\n",
            "+--------------------------------------------------------+----------+\n",
            "|Animation|Documentary                                   |5.0       |\n",
            "|Action|Adventure|Animation|Comedy|Fantasy|Mystery|Sci-Fi|5.0       |\n",
            "|Crime|Documentary|War                                   |5.0       |\n",
            "|Adventure|Fantasy|Mystery                               |5.0       |\n",
            "|Crime|Horror|Mystery                                    |4.75      |\n",
            "|Adventure|Comedy|Fantasy|Musical                        |4.5       |\n",
            "|Animation|Comedy|Horror|IMAX                            |4.5       |\n",
            "|Adventure|Crime|Drama|Horror|Mystery                    |4.5       |\n",
            "|Adventure|Comedy|Crime|Drama|Romance                    |4.5       |\n",
            "|Action|Animation|Crime|Sci-Fi|Thriller                  |4.5       |\n",
            "+--------------------------------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Calculate average ratings for each genre, and plot average ratings of top 10 genres with descending order\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Calculate the average rating for each genre\n",
        "genre_rating_avg_df = ratings_movies_df.groupBy(\"genres\").agg(\n",
        "    F.avg(\"rating\").alias(\"rating_avg\")\n",
        ")\n",
        "\n",
        "# Sort the dataframe by rating_avg column\n",
        "genre_rating_avg_df.sort(\"rating_avg\", ascending=False).show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M2z4B1ZubTP"
      },
      "source": [
        "## TASK 2 - Recommender Design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Hd6rfJRvuf0U"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w0YoCcJzPkrB"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"movieRecommendation\").getOrCreate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "XlqTJcjFSdHr",
        "outputId": "4f9bf3d2-7be9-42f8-af34-eb03fc282028"
      },
      "outputs": [],
      "source": [
        "# using movie rating data to probide implicit feature using ALS(Alternate Least Squares)\n",
        "\n",
        "movie_rating_df = ratings_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sHsJtxjKL9A",
        "outputId": "0d4470c6-577b-47d7-94be-fb36f80937d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- movieId: long (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# description of created schema \n",
        "movie_rating_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k0xQG5w9ryG8"
      },
      "outputs": [],
      "source": [
        "#splitting dataset to train the model as 80% for train and remaining for test data.\n",
        "(train, test) = movie_rating_df.randomSplit([0.8, 0.2], seed=87)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGTNsGakWNl6",
        "outputId": "09fa8371-5c7b-425b-de3b-0cb88923645b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 15:00:07 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
            "24/01/23 15:00:07 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
            "24/01/23 15:00:07 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
            "24/01/23 15:00:07 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
            "[Stage 138:===================================================> (196 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|implicit |\n",
            "+------+-------+------+---------+\n",
            "|31    |471    |4.5   |1.8935201|\n",
            "|159   |471    |4.0   |3.7890081|\n",
            "|348   |471    |4.0   |2.2790236|\n",
            "|40    |471    |4.0   |3.997721 |\n",
            "|447   |471    |5.0   |3.0354795|\n",
            "|489   |471    |5.0   |3.5236747|\n",
            "|114   |471    |4.0   |3.1626875|\n",
            "|100   |471    |4.0   |3.3876393|\n",
            "|450   |471    |2.0   |2.8211172|\n",
            "|555   |471    |3.5   |4.635881 |\n",
            "|7     |471    |4.0   |3.3934188|\n",
            "|214   |471    |3.0   |2.947355 |\n",
            "|221   |471    |5.0   |3.4761927|\n",
            "|284   |471    |1.0   |3.36733  |\n",
            "|153   |471    |3.0   |3.7567434|\n",
            "|199   |833    |5.0   |3.5096498|\n",
            "|596   |1088   |3.0   |2.5451236|\n",
            "|696   |1088   |5.0   |4.0491714|\n",
            "|581   |1088   |4.0   |4.068609 |\n",
            "|339   |1088   |4.5   |2.9458978|\n",
            "+------+-------+------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# 1st Recommender model - Alternating Least Square (ALS) Matrix Factorization in Collaborative Filtering on rating (as actual values) \n",
        "\n",
        "als = ALS(rank=10, maxIter=15, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "\n",
        "model = als.fit(train)\n",
        "\n",
        "pred = model.transform(test)\n",
        "\n",
        "pred = pred.selectExpr(\"userId as userId\",\"movieId as movieId\",\"rating as rating\",\"prediction as implicit\")\n",
        "\n",
        "pred.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IxWorgqcUIO",
        "outputId": "bf56b94f-7c1b-4cb9-fc51-04d2eb244d95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 216:=================================================>   (186 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE of ALS: 1.2222768603660332\n",
            "MAE of ALS: 0.90745209519291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#calculating RMSE and MAE to evaluate performance of the models. \n",
        "\n",
        "eval_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"implicit\")\n",
        "eval_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"implicit\")\n",
        "\n",
        "\n",
        "rmse = eval_rmse.evaluate(pred)\n",
        "mae = eval_mae.evaluate(pred)\n",
        "\n",
        "\n",
        "print(\"RMSE of ALS:\", rmse)\n",
        "print(\"MAE of ALS:\", mae)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiveQdC4vbT-",
        "outputId": "792174a8-f360-48ab-9e95-b73b6c8f1410"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 554:=================================================>   (185 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+------+---------+----------+\n",
            "|userId|movieId|rating|implicit |prediction|\n",
            "+------+-------+------+---------+----------+\n",
            "|159   |471    |4.0   |3.7890081|2.794365  |\n",
            "|489   |471    |5.0   |3.5236747|4.941455  |\n",
            "|114   |471    |4.0   |3.1626875|2.0920568 |\n",
            "|214   |471    |3.0   |2.947355 |3.9414387 |\n",
            "|221   |471    |5.0   |3.4761927|3.3370953 |\n",
            "|284   |471    |1.0   |3.36733  |3.0591292 |\n",
            "|596   |1088   |3.0   |2.5451236|1.120658  |\n",
            "|339   |1088   |4.5   |2.9458978|1.9720254 |\n",
            "|416   |1580   |5.0   |4.1063194|2.7542517 |\n",
            "|48    |1580   |5.0   |4.592147 |3.13164   |\n",
            "|37    |1580   |4.5   |2.7149873|4.3887815 |\n",
            "|438   |1580   |4.0   |3.104217 |3.0729005 |\n",
            "|384   |1591   |2.5   |2.1793556|1.8413986 |\n",
            "|246   |1591   |3.5   |3.771912 |1.8602619 |\n",
            "|384   |1645   |3.5   |3.6046662|4.448451  |\n",
            "|8     |1645   |3.0   |4.1210723|4.0557103 |\n",
            "|354   |1645   |4.0   |4.369527 |0.9570819 |\n",
            "|665   |3175   |5.0   |4.204756 |4.3620677 |\n",
            "|320   |3175   |3.0   |2.672224 |2.650245  |\n",
            "|221   |3175   |4.5   |5.878103 |3.6871874 |\n",
            "+------+-------+------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# 2nd Recommender model - Alternating Least Square (ALS) Matrix Factorization in Collaborative Filtering on designed implicit feedback values \n",
        "\n",
        "\n",
        "(train_implicit, test_implicit) = pred.randomSplit([0.8, 0.2], seed=87)\n",
        "\n",
        "als_implicit = ALS(rank=10, maxIter=15, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"implicit\", coldStartStrategy=\"drop\")\n",
        "\n",
        "model_implicit = als_implicit.fit(train_implicit)\n",
        "\n",
        "pred_implicit = model_implicit.transform(test_implicit)\n",
        "\n",
        "pred_implicit.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oUlsznN7MGh",
        "outputId": "b1757443-91a5-44e8-8f03-32982684794f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 714:====================================================>(198 + 2) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE of ALS_Implicit Feedback: 1.7470276604705446\n",
            "MAE of ALS_Implicit Feedback: 1.3695158293566574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "eval_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "eval_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "\n",
        "rmse = eval_rmse.evaluate(pred_implicit)\n",
        "mae = eval_mae.evaluate(pred_implicit)\n",
        "\n",
        "\n",
        "print(\"RMSE of ALS_Implicit Feedback:\", rmse)\n",
        "print(\"MAE of ALS_Implicit Feedback:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imQMCTu799AA"
      },
      "source": [
        "When compared these two models, the 1st model ( ALS on rating ) shows better performance compared to 2nd model (ALS on implicit feedback) according to error metrics such as Root Mean Square Error (RMSE) and Mean Absolute Error (MAE). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeRDX3e3-4z5"
      },
      "source": [
        "## Task â€“ 3 Text Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mY-LEz8E-8CP"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"textAnalysis\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zXVe2XVGHOut"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import col, udf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  7287k      0  0:00:11  0:00:11 --:--:-- 15.0M\n"
          ]
        }
      ],
      "source": [
        "# download the data in Dataset folder.\n",
        "\n",
        "\n",
        "\n",
        "!curl -o Datasets/aclImdb_v1.tar.gz https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_13BV8pDCDiN",
        "outputId": "d7ac9527-f4af-4524-824a-f5a679f38650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining files: 000000\n",
            "Extraction completed.\n"
          ]
        }
      ],
      "source": [
        "#Extract the tar file as dataset\n",
        "\n",
        "import tarfile\n",
        "\n",
        "def tarfile_extract(tar_file, output_dir=os.getcwd()+'/Datasets'):\n",
        "    tar = tarfile.open(tar_file, 'r:gz')\n",
        "    total_files = sum(1 for _ in tar)\n",
        "    tar.extractall(output_dir, members=extract_progress(tar, total_files))\n",
        "    tar.close()\n",
        "\n",
        "def extract_progress(tar, total_files):\n",
        "    for member in tar:\n",
        "        yield member\n",
        "        total_files -= 1\n",
        "        print(f\"Remaining files: {total_files}\", end='\\r')\n",
        "    print(\"\\nExtraction completed.\")\n",
        "\n",
        "wd = os.getcwd()\n",
        "tarfile_extract(wd+'/Datasets/aclImdb_v1.tar.gz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "K7ezNM9_W3jQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#using 'alldata' list to store all the files in the directories\n",
        "alldata=[]\n",
        "\n",
        "\n",
        "#collecting data in train/pos folder\n",
        "for fname in os.listdir(wd+'/Datasets/aclImdb/train/pos'):\n",
        "    with open(os.path.join(wd+'/Datasets/aclImdb/train/pos', fname), encoding = 'utf-8') as infile:\n",
        "        for line in infile:\n",
        "            alldata.append((line,'train','pos'))\n",
        "\n",
        "#collecting data in train/neg folder\n",
        "for fname in os.listdir(wd+'/Datasets/aclImdb/train/neg'):\n",
        "    with open(os.path.join(wd+'/Datasets/aclImdb/train/neg', fname), encoding = 'utf-8') as infile:\n",
        "        for line in infile:\n",
        "            alldata.append((line,'train','neg'))\n",
        "#collecting data in test/pos folder\n",
        "for fname in os.listdir(wd+'/Datasets/aclImdb/test/pos'):\n",
        "    with open(os.path.join(wd+'/Datasets/aclImdb/test/pos', fname), encoding = 'utf-8') as infile:\n",
        "        for line in infile:\n",
        "            alldata.append((line,'test','pos'))\n",
        "#collecting data in test/neg folder\n",
        "for fname in os.listdir(wd+'/Datasets/aclImdb/test/neg'):\n",
        "    with open(os.path.join(wd+'/Datasets/aclImdb/test/neg', fname), encoding = 'utf-8') as infile:\n",
        "        for line in infile:\n",
        "            alldata.append((line,'test','neg'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uH1TGbjlh7o",
        "outputId": "c43c9ce1-1a78-41f4-8034-1c3e5b3c537f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StructType(List(StructField(content,StringType,true),StructField(label,StringType,true),StructField(sentiemtn,StringType,true)))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 15:02:36 WARN TaskSetManager: Stage 716 contains a task of very large size (32123 KiB). The maximum recommended task size is 1000 KiB.\n",
            "[Stage 716:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+---------+\n",
            "|             content|label|sentiemtn|\n",
            "+--------------------+-----+---------+\n",
            "|Man, this is a ha...|train|      pos|\n",
            "|The Color Purple ...|train|      pos|\n",
            "|Randolph Scott is...|train|      pos|\n",
            "|High energy Raoul...|train|      pos|\n",
            "|One of the great ...|train|      pos|\n",
            "|Although I'm grat...|train|      pos|\n",
            "|It is hard to des...|train|      pos|\n",
            "|- Having grown ti...|train|      pos|\n",
            "|This movie is fun...|train|      pos|\n",
            "|It was considered...|train|      pos|\n",
            "|Other commentator...|train|      pos|\n",
            "|I saw this movie ...|train|      pos|\n",
            "|So i consider mys...|train|      pos|\n",
            "|My mother took me...|train|      pos|\n",
            "|After 21 movies a...|train|      pos|\n",
            "|I have a six mont...|train|      pos|\n",
            "|...On stage, TV o...|train|      pos|\n",
            "|I had to see this...|train|      pos|\n",
            "|Although at one p...|train|      pos|\n",
            "|Hot Millions is a...|train|      pos|\n",
            "+--------------------+-----+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType\n",
        "\n",
        "appName = \"list to Spark Data Frame\"\n",
        "master = \"local\"\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(appName) \\\n",
        "    .master(master) \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# List\n",
        "data = alldata\n",
        "\n",
        "# Create a schema for the dataframe\n",
        "schema = StructType([\n",
        "    StructField('content', StringType(), True),\n",
        "    StructField('label', StringType(), True),\n",
        "    StructField('sentiemtn', StringType(), True)\n",
        "])\n",
        "\n",
        "# Convert list to RDD\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "\n",
        "# Create data frame\n",
        "df = spark.createDataFrame(rdd,schema)\n",
        "print(df.schema)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7DUME6Xx1Hx",
        "outputId": "fb816dd9-aaf3-4af3-b678-577c5bbfa3b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 15:02:38 WARN TaskSetManager: Stage 717 contains a task of very large size (32123 KiB). The maximum recommended task size is 1000 KiB.\n",
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JoFIyowyMjB",
        "outputId": "ff0c2ad5-97bf-4773-c4b8-9bffe15c187c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- content: string (nullable = true)\n",
            " |-- label: string (nullable = true)\n",
            " |-- sentiemtn: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Schema of created Spark Dataframe\n",
        "\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPXsyhn_2QZC"
      },
      "source": [
        "###Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK1PwZq5yhfK",
        "outputId": "e8f45810-67b3-4db0-bfc9-0c8656d7ca26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 15:02:39 WARN TaskSetManager: Stage 719 contains a task of very large size (32123 KiB). The maximum recommended task size is 1000 KiB.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+---------+--------------------+\n",
            "|             content|label|sentiemtn|   tokenized_content|\n",
            "+--------------------+-----+---------+--------------------+\n",
            "|Man, this is a ha...|train|      pos|[man, this, is, a...|\n",
            "|The Color Purple ...|train|      pos|[the, color, purp...|\n",
            "|Randolph Scott is...|train|      pos|[randolph, scott,...|\n",
            "|High energy Raoul...|train|      pos|[high, energy, ra...|\n",
            "|One of the great ...|train|      pos|[one, of, the, gr...|\n",
            "|Although I'm grat...|train|      pos|[although, i, m, ...|\n",
            "|It is hard to des...|train|      pos|[it, is, hard, to...|\n",
            "|- Having grown ti...|train|      pos|[having, grown, t...|\n",
            "|This movie is fun...|train|      pos|[this, movie, is,...|\n",
            "|It was considered...|train|      pos|[it, was, conside...|\n",
            "|Other commentator...|train|      pos|[other, commentat...|\n",
            "|I saw this movie ...|train|      pos|[i, saw, this, mo...|\n",
            "|So i consider mys...|train|      pos|[so, i, consider,...|\n",
            "|My mother took me...|train|      pos|[my, mother, took...|\n",
            "|After 21 movies a...|train|      pos|[after, 21, movie...|\n",
            "|I have a six mont...|train|      pos|[i, have, a, six,...|\n",
            "|...On stage, TV o...|train|      pos|[on, stage, tv, o...|\n",
            "|I had to see this...|train|      pos|[i, had, to, see,...|\n",
            "|Although at one p...|train|      pos|[although, at, on...|\n",
            "|Hot Millions is a...|train|      pos|[hot, millions, i...|\n",
            "+--------------------+-----+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#using RegexTokenizer for tokenizing contents\n",
        "\n",
        "tokenizer = RegexTokenizer(inputCol=\"content\", outputCol=\"tokenized_content\", pattern=\"\\\\W\") # used regexp to determine pattern as 'not word'\n",
        "\n",
        "countTokens = udf(lambda w: len(w), IntegerType())\n",
        "\n",
        "tokenized = tokenizer.transform(df)\n",
        "\n",
        "tokenized.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf-Omq8n15FM"
      },
      "source": [
        "### Removing Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NcWM3ek-iph",
        "outputId": "ead4cd37-4991-4f5d-ee5a-3c658913581c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtoV10AW1uN6",
        "outputId": "36fc2c88-3b56-44d6-e93f-99565adab26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+---------+--------------------+\n",
            "|             content|label|sentiemtn|   tokenized_content|\n",
            "+--------------------+-----+---------+--------------------+\n",
            "|Man, this is a ha...|train|      pos|[man, this, is, a...|\n",
            "|The Color Purple ...|train|      pos|[the, color, purp...|\n",
            "|Randolph Scott is...|train|      pos|[randolph, scott,...|\n",
            "|High energy Raoul...|train|      pos|[high, energy, ra...|\n",
            "|One of the great ...|train|      pos|[one, of, the, gr...|\n",
            "|Although I'm grat...|train|      pos|[although, i, m, ...|\n",
            "|It is hard to des...|train|      pos|[it, is, hard, to...|\n",
            "|- Having grown ti...|train|      pos|[having, grown, t...|\n",
            "|This movie is fun...|train|      pos|[this, movie, is,...|\n",
            "|It was considered...|train|      pos|[it, was, conside...|\n",
            "|Other commentator...|train|      pos|[other, commentat...|\n",
            "|I saw this movie ...|train|      pos|[i, saw, this, mo...|\n",
            "|So i consider mys...|train|      pos|[so, i, consider,...|\n",
            "|My mother took me...|train|      pos|[my, mother, took...|\n",
            "|After 21 movies a...|train|      pos|[after, 21, movie...|\n",
            "|I have a six mont...|train|      pos|[i, have, a, six,...|\n",
            "|...On stage, TV o...|train|      pos|[on, stage, tv, o...|\n",
            "|I had to see this...|train|      pos|[i, had, to, see,...|\n",
            "|Although at one p...|train|      pos|[although, at, on...|\n",
            "|Hot Millions is a...|train|      pos|[hot, millions, i...|\n",
            "+--------------------+-----+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 15:02:40 WARN TaskSetManager: Stage 720 contains a task of very large size (32123 KiB). The maximum recommended task size is 1000 KiB.\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "tokenized.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IN6Qe86F4cPF"
      },
      "outputs": [],
      "source": [
        "df_tokenized = tokenized.select(\"tokenized_content\").withColumn(\"tokenCount\", countTokens(col(\"tokenized_content\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6gu2PKO9bkw",
        "outputId": "21a74ae9-84cd-494c-f73d-67eaeac6a24a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1JaxUOh3eIL",
        "outputId": "906b1c9e-4510-43cf-8b02-dd2d89ecbb6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/23 15:02:40 WARN TaskSetManager: Stage 721 contains a task of very large size (32123 KiB). The maximum recommended task size is 1000 KiB.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|SWRed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[man, hard, dvd, come, find, region, 2, spanish, import, expensive, br, br, worth, well, yes, much, masterpiece, film, making, though, directed, curt, siodmak, credits, imdb, com, read, robert, dvd, credits, list, curt, couple, familiar, figures, murder, mysteries, elisha, cook, jr, thomas, gomez, decade, long, curiosity, movie, finally, satisfied, br, br, essentially, respected, self, contained, engineer, alan, curtis, stood, estranged, wife, finds, new, york, bar, two, show, tickets, pocket, woman, strange, hat, stool, next, politely, invites, join, musical, review, accepts, little, gloomily, mopey, bartender, gives, eye, leave, br, br, show, tempestuous, star, notices, lady, audience, wearing, hat, erupts, offstage, anger, drummer, band, cook, leers, silent, lady, gets, response, curtis, takes, woman, home, asks, name, won, give, doesn, want, know, d, longfellow, devotee, d, said, something, ships, pass, night, br, br, okay, curtis, goes, home, find, wife, murdered, absence, head, police, officer, gomez, turns, da, alibi, phantom, lady, one, else, seems, remember, bartender, latina, star, cab, driver, al, alp, drummer, since, lady, disappeared, impossible, dig, br, br, curtis, convicted, sentenced, die, inspector, gomez, thought, things, decided, probably, innocent, nobody, brain, make, stupid, story, joins, curtis, loving, secretary, ella, raines, re, investigating, case, informally, br, br, visit, supposed, witnesses, ominous, bartender, run, car, perhaps, accidentally, picture, hot, tempered, latina, left, show, closed, uncooperative, ignorant, source, hat, anyway, elisha, cook, jr, strangled, real, murderer, featured, scene, pounds, drums, improvised, jazz, group, sweaty, face, assumes, expression, doesn, suggest, intense, focus, rather, monstrous, orgasmic, insanity, eyeballs, roll, ceiling, mouth, gapes, hammering, becomes, frenzied, laughed, loud, br, br, nobody, performance, otherwise, outstanding, professional, enough, thomas, gomez, always, reliable, best, performance, though, probably, franchot, tone, real, murderer, fakes, alibi, reserved, artistic, even, faints, decorous, know, put, precisely, tone, seems, thinking, well, simply, acting, part, alan, curtis, innocent, engineer, near, zero, kelvin, scale, belongs, b, picture, br, br, know, considered, classic, really, basic, murder, mystery, cornell, woolrich, good, others, siodmak, direction, sensitive, man, gets, run, hat, winds, gutter, water, running, around, use, shadows, quietly, effective, br, br, glad, got]|\n",
            "|[color, purple, masterpiece, displays, amazing, acting, abilities, whoopi, goldberg, oprah, winfrey, danny, glover, steven, spielberg, incredible, director, time, versatility, shines, film, ever, want, see, movie, watch, beautiful, portrayal, one, moving, stories, time]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|[randolph, scott, heading, albuquerque, take, job, uncle, however, way, stage, held, even, though, carrying, strongbox, however, nice, lady, board, concealing, 10, 000, brother, business, robbers, seem, know, br, br, town, scott, goes, uncle, job, however, soon, learns, uncle, jerk, typical, bad, guy, westerns, know, rich, guy, wants, become, richer, cheating, stealing, threatening, owns, everything, happens, jerk, behind, robbery, scott, demands, uncle, returns, money, scott, goes, business, nice, lady, brother, br, br, surprisingly, end, problems, beginning, intrigues, various, types, occur, try, crush, uncle, opposition, one, trick, bring, pretty, lady, befriend, scott, partners, crack, shot, looks, bad, scott, figures, come, town, br, br, unlike, later, randolph, scott, films, one, shows, scott, bit, headstrong, man, often, films, last, one, suggest, violence, film, quick, suggest, lynching, screw, law, let, hangin, later, quick, threaten, uncle, surprise, see, hot, head, though, ways, old, scott, d, expect, br, br, far, film, goes, nothing, particularly, unusual, gabby, hayes, plays, usual, character, scott, hero, baddie, reasoned, ultimately, destroyed, scott, gets, girl, despite, typical, plot, handled, well, result, well, worth, time, br, br, way, two, weird, scenes, film, first, late, movie, fist, fight, scott, uncle, 1, henchman, lon, chaney, jr, chaney, smokes, fights, something, never, saw, admire, puff, away, got, butt, kicked, second, get, load, runaway, cart, scene, whip, one, impossible, feat]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|[high, energy, raoul, walsh, classic, 1933, bowery, places, saloon, owner, operator, wallace, beery, bitter, rival, dandy, george, raft, adopted, street, kid, jackie, cooper, good, looking, faye, wray, roles, play, big, rivalry, clear, exactly, rivalry, everyone, follows, daily, tabloids, plenty, wisecracks, beginning, characters, soften, film, progresses, apart, sheer, exuberance, scenes, beery, saloon, various, characters, sexy, chorus, line, lots, drinking, perfect, creation, den, iniquity, refrained, called, pre, code, restrictions, later, come, carrie, nations, led, carrie, nation, creates, vivid, picture, life, long, gone, like, compare, eras, film, completely, totally, different, anything, one, see, today, film, plenty, heart, long, lost, innocence, absolutlely, must, see]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|[one, great, mysteries, life, suffered, daily, nice, girls, often, interested, jerks, heels, nice, guys, br, br, worse, nice, guys, even, want, marry, girls, girls, still, prefer, jerks, heels, even, jerks, heels, shown, contempt, shown, re, interested, using, girls, br, br, stu, erwin, nice, guy, continues, nice, lied, cheated, even, losing, girl, completely, br, br, clark, gable, jerk, perfect, role, rather, sad, note, fans, br, br, jean, harlow, comes, across, slender, mae, west, even, sounding, like, la, west, cynical, throwaway, lines, br, br, somewhat, puzzling, many, characters, intended, bad, guys, mean, heck, re, locked, must, obviously, nice, people, br, br, fact, lots, nice, people, people, lesser, film, story, snarling, back, stabbing, go, way, help, someone, else, br, br, maybe, story, rather, clich, d, least, modern, standards, ultimately, viewer, glad, watched, br, br, biggest, complaint, many, really, good, actors, given, credit, say, fervent, thank, imdb, com]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "|[although, m, grateful, obscure, gem, 70, italian, exploitation, cinema, features, recently, released, grindhouse, experience, box, set, although, also, available, disc, misleading, stupid, alternate, title, escape, death, row, honestly, think, deserves, proper, luxurious, dvd, edition, completely, originally, spoken, languages, subtitle, options, dubbing, truly, horrible, restored, picture, quality, truckload, special, bonus, features, heck, even, need, restored, picture, quality, bonus, features, watch, film, original, language, mean, frank, crazy, tony, cheerfully, fast, paced, mafia, crime, flick, lot, violence, comedy, admittedly, doesn, always, work, feminine, beauty, two, witty, main, characters, tony, lo, bianco, terrific, small, thug, pretending, city, biggest, real, crime, lord, frankie, dio, lee, van, cleef, arrives, town, sees, opportunity, climb, ladder, offering, services, frankie, initially, ignores, little, crook, eventually, form, unlikely, team, frankie, entire, criminal, empire, turns, new, french, criminal, mastermind, even, assassinates, frankie, innocent, brother, tony, helps, frankie, escape, prison, together, head, marseille, extract, frankie, revenge, script, sadly, neglected, crime, gem, funnily, alters, gritty, action, suspense, light, headed, bits, comedy, like, grotesque, car, chase, narrow, french, mountain, roads, example, build, towards, typical, mafia, execution, sequences, guided, excellent, riz, ortolani, score, extremely, tense, actual, killings, sadistic, merciless, probably, film, considered, somewhat, grindhouse, classic, film, lacks, strong, female, lead, lovely, amazingly, voluptuous, beauty, edwige, fenech, sadly, appears, couple, scenes, still, background, men, behind, camera, responsible, superb, cinematography, less, joe, d, amato, great, film, highly, recommended, fans, italian, exploitation, hope, watch, soon, original, version]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|[hard, describe, bug, words, one, films, truly, seen, understood, follows, narrative, fluid, interesting, anything, seen, lately, hollywood, release, characters, react, chain, events, different, ways, events, dictate, different, paths, characters, follow, audience, merely, observer, almost, proustian, narrative, flow, thought, thought, spontaneity, script, glued, screen, waiting, anxiously, see, works, end, far, thematic, elements, particular, sequence, film, goes, melancholy, bright, beautiful, tragic, within, span, minute, works, br, br, movie, pure, magic, reminds, one, independent, film, perhaps, brightest, star, film, industry, currently, perhaps, movies, bug, quality, people, start, take, notice]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|[grown, tired, rat, race, cramped, living, conditions, new, york, city, jim, blandings, cary, grant, finds, property, country, wife, children, hoping, find, simple, life, building, house, proves, anything, simple, headaches, bills, start, piling, laughs, mr, blanding, ever, get, dream, house, br, br, makes, movie, special, three, main, actors, grant, myrna, loy, melvyn, douglas, three, capable, carrying, movie, combine, talents, almost, every, scene, special, grant, always, favorite, mine, type, role, good, playing, put, upon, husband, loy, always, joy, watch, thin, man, films, made, william, powell, near, perfect, douglas, become, favorite, mine, last, two, three, years, douglas, also, appeared, old, dark, house, particular, favorite, mine, br, br, movie, definitely, product, time, get, kick, imagining, time, build, two, story, three, bedroom, four, bathroom, house, 15, 000, income, year, throw, fact, two, children, attend, private, school, live, maid, becomes, almost, fanciful, br, br, however, anyone, bought, built, house, many, situations, predicaments, blanding, find, easily, relatable, today, comedy, comes, many, people, done, stupid, things, couple, movie, end, costing, money, expected, biggest, complaint, mr, blandings, whole, wife, love, best, friend, subplot, really, necessary, plot, feels, place, uncomfortable, presented]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|[movie, funny, suitable, age, definitely, family, type, entertainment, cast, fine, job, playing, folks, mid, western, town, big, bean, illinois, must, assume, nothing, ever, happens, since, excitement, pre, invasion, decade, new, exit, ramp, interstate, location, appeals, suitably, boring, totally, unlikely, invasion, earth, martians, martians, totally, inept, despite, well, equipped, arsenal, suitably, ghastly, deadly, weapons, including, one, set, eradicating, martians, martians, dead, pan, lines, throw, right, accents, make, us, viewers, locals, wish, help, leave, earth, j, j, anderson, playing, young, halloween, carnivorous, duck, great, lines, watch, movie, laugher, entertainment, thought, provoking, isn, subtle, enjoyable]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|[considered, swiss, answer, lord, rings, much, isn, answer, anything, something, new, something, funny, sometimes, downright, stupid, silly, monty, python, different, silly, br, br, beginning, immediately, makes, statement, film, low, budget, meant, taken, entirely, seriously, cardboard, clouds, strings, knock, airplane, main, character, seated, compensate, missing, special, effects, landscape, trick, absolutely, beautiful, stunning, needs, new, zealand, switzerland, br, br, liked, film, simple, approach, obvious, passion, energy, went, isn, brilliant, yet, got, good, humorous, parts, edward, piccin, friedo, absolutely, convincing, enough, go, see, film, good, jokes, lame, won, understood, people, outside, switzerland, liked, idea, urucows, instead, uruk, hai, loved, scene, friedo, decides, take, pupsi, telehobbie, journey, also, funny, scene, rackaroll, sword, fighting, knight, decides, show, sword, subsequently, smashes, wall, breaking, one, scene, nazgul, ish, characters, wonderfully, comic, scene, includes, toilet, brush, didn, approve, idea, ring, used, schleimli, gollum, character, order, seduce, ladies, bit, far, fetched, idea, lord, sauraus, wanting, cover, lands, fondue, wasn, brilliant, either, original, certainly, brilliant, dislike, idea, gay, dragon, really, wasn, necessary, recommend, see, film, simply, crazy, totally, trashy, expect, lotr, parody, like, spaceballs, star, wars, go, flicks, thinking, going, amusing, evening, absolutely, ambitions, ll, enjoy, sure, works, languages, live, swiss, dialects, well, jokes, actors, br, br, hat, courage, swiss, crew]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|[commentators, detailed, plot, social, parables, commentary, well, better, like, join, admiration, little, jewel, film, holds, well, indeed, 50, years, later, every, category, screenplay, acting, photography, set, design, sound, design, really, classic, sorts, first, exposure, young, alec, guinness, obvious, first, frames, made, special, eventually, receive, knighthood, br, br, rate, 8, essentially, rather, lightweight, parable, examines, human, nature, doesn, really, skewer, plot, takes, easy, way, end, rather, actually, resolving, conflict, inventor, mill, workers, industrialists, chasing, town, also, couple, minutes, thought, reveals, basic, flaw, logic, screenplay, wear, tear, hardly, ever, determining, factor, buying, new, clothes, especially, dress, clothes, children, grow, people, change, sizes, gain, lose, weight, go, latest, fashions, time, long, looms, woven, cloth, nothing, else, manufacturer, make, fortune, providing, indestructible, material, military, uniforms, especially, bdus, br, br, still, great, film, get, chance, see, classic, movie, channel]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|[saw, movie, family, great, film, documentary, offers, cold, facts, long, mono, duologue, lots, charts, complete, power, movie, comes, impressive, pictures, filmed, water, air, arctic, watching, movie, learn, planet, reading, book, shows, embedded, circular, flow, life, movie, environmental, fanatics, although, people, want, look, good, movie, message, watch, movie, taught, living, earth, live, earth, plants, animals, grow, die, us]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|[consider, pretty, big, anime, scene, shows, simply, watch, br, br, show, however, recommend, anyone, br, br, quite, possibly, original, series, date, got, everything, ask, side, story, speak, unconditional, love, admitted, blatant, comedy, well, put, together, voice, acting, cast, japanese, american, translation, br, br, terribly, funny, aspect, another, anime, br, br, less, noticed, love, hate, people, seen, introduced, series, end, distaste, br, br, original, core, everything, ask, afternoon, bet, house, series, m, ready, assure, enjoy]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|[mother, took, see, film, child, long, see, every, year, christmas, favorites, remember, silly, devil, santa, looking, telescope, waited, looked, v, guide, year, see, shown, usually, find, playing, saturday, afternoon, found, movie, english, took, something, special, away, film, longed, find, copy, spanish, hold, film, dear, heart, never, suffered, nightmares, others, might, suggest, yes, different, film, santa, claus, makes, special, unique, wait, get, copy, film, watch, children, explain, favorite, parts, memories]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|[21, movies, three, years, working, hollywood, bette, davis, finally, got, role, claimed, put, force, reckoned, mildred, rogers, davis, burst, forth, completely, unsympathetic, role, slutty, waitress, becomes, target, leslie, howard, affections, already, eager, sink, teeth, role, like, qualms, awful, things, character, meant, throughout, course, film, awful, transformation, undergo, also, widely, noted, performance, one, things, makes, slightly, uneven, movie, watchable, one, remember, even, two, remakes, scenes, rips, howard, made, cinema, history, br, br, circa, 85, minutes, story, moves, nice, pace, telling, story, philip, carey, howard, life, crosses, destructive, mildred, rogers, br, br, howard, davis, chemistry, non, existent, davis, sustained, interview, much, later, life, personally, didn, care, much, howard, iciness, towards, helped, act, even, worse, character, towards, mildred, two, seem, awkward, one, another, scenes, together, remain, stiff, salvaged, ferocious, acidity, davis, brings, lines, nervous, presence, cromwell, direction, certain, stiltedness, fails, come, times, tries, fill, space, whenever, davis, dissolves, montages, indicating, passing, time, calendar, superimposed, changing, frances, dee, much, style, back, technicalities, complicated, camera, angles, came, essence, visual, story, simplified, bare, essentials, translation, somerset, maugham, novel, saying, lot, since, 600, pages, human, bondage, indeed, hard, film, even, br, br, storywise, feels, philip, carey, may, something, glutton, punishment, since, discernible, sexual, attraction, mildred, compound, mildred, never, hides, displeasure, get, go, howard, performance, never, seems, go, much, external, emotion, eyes, constantly, sad, expression, never, veers, far, away, lost, almost, distant, cousin, william, hurt, accidental, tourist, dejected, hurt, absolutely, passive, possibly, part, character, reason, fails, see, women, played, kay, johnson, frances, dee, making, vulnerable, unrequited, affections, interestingly, johnson, norah, realizes, carey, never, fall, one, sums, story, observation, people, bound, people, bound, carey, carey, bound, mildred, mildred, bound, miller, men, fit, role, provider, short, memorable, scene, one, holds, essence, story, moral]                                                                                                                                                                                                                                                     |\n",
            "|[six, month, old, baby, home, time, time, fights, sleep, really, bad, one, morning, particular, difficult, time, getting, sleep, doodle, bops, theme, song, came, v, stopped, crying, almost, instantly, rest, show, content, sat, bouncy, seat, watched, kick, legs, swing, arms, actually, laugh, show, kept, entertained, happy, entire, time, also, got, video, times, little, one, flustered, something, calm, granted, late, night, awakes, colic, fuss, doodle, bops, cup, tea, sure, come, handy, need, little, time, housework, etc, biggest, surprise, doodle, bops, child, doesn, even, like, watching, v, d, rather, floor, playing, toy, small, toy, poodle, watch, v, yet, doodle, bops, totally, captured, attention, know, continue, like, future, attached]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|[stage, tv, book, woman, black, outstanding, ghost, story, reviewers, already, said, say, film, thought, add, belated, little, review, made, tv, movie, deliberately, slow, first, act, chronicles, main, character, arthur, goes, business, solicitor, 1920s, london, understand, might, appeal, palates, nevertheless, love, british, style, storytelling, similar, bbc, ghost, story, christmas, adaptations, great, m, r, james, work, second, act, ghost, story, kicks, arthur, sent, provinces, boss, tidy, affairs, deceased, client, third, act, relentlessly, builds, spine, tingling, conclusion, londoner, seen, play, book, dvd, r, unabridged, audio, book, ipod, sure, women, black, medium, ghost, story, equals, time, legitimate, region, 2, dvd, release]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|[see, gem, twice, really, appreciate, widowed, father, two, interrupts, two, sons, sleep, shocking, revelation, torn, believing, horrifying, events, tale, unfold, learn, lot, father, two, sons, destinies, shocking, twist, shocking, twist, film, never, allows, lull, plot, bill, paxton, plays, father, notable, performances, older, son, fenton, played, matthew, o, leary, younger, son, adam, played, jeremy, sumpter, one, best, thrillers, seen, want, watch, times, appreciate, every, intricate, aspect, plot, give, film, 9, 10]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|[although, one, point, thought, going, turn, graduate, say, mother, excellent, job, explaining, sexual, desires, older, woman, br, br, m, glad, british, film, hollywood, never, done, even, ruined, taking, time, develop, characters, br, br, story, revealed, slowly, realistically, acting, superb, characters, believably, flawed, dialogue, sensitive, tried, many, times, predict, going, happen, always, wrong, intrigued, story, br, br, highly, recommend, movie, must, confess, ll, forever, look, mom, different, light]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|[hot, millions, great, movie, every, way, fun, offbeat, story, wonderful, performances, four, best, professionals, ever, work, business, peter, ustinov, brilliant, usual, maggie, smith, definitely, one, greatest, actresses, time, total, delight, karl, malden, bob, newhart, round, cast, also, perfect, want, movie, perfect, casting, impressive, way, people, work, natural, effortless, way, creating, lots, laughs, fun, moments, throughout, peter, ustinov, genius, wonderful, sense, humor, one, memorable, performances, direction, photography, editing, also, first, rate, great, time, capsule, london, 60s, definitely, time, favorites, list]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SWR -> stop word remover\n",
        "SWR  = StopWordsRemover (inputCol='tokenized_content', outputCol='SWRed')\n",
        "\n",
        "\n",
        "#See the result of removal operation\n",
        "SWR.transform(df_tokenized).select('SWRed').show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Huawei R&D Technical Interview Question_v2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
